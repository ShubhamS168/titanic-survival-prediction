# ðŸš¢ Deploying Machine Learning Models with Streamlit â€“ Titanic Survival Prediction

## ðŸ“˜ Overview

This project demonstrates a **production-ready machine learning deployment pipeline** using **Streamlit** to predict Titanic passenger survival based on engineered features and optimized models. The app enables real-time predictions, model explanations via SHAP, and intuitive dashboards for users.

> ðŸ“Œ **Note**: This project was developed as part of the **Week 7 Assignment** in the **Celebal Summer Internship** program.

The solution showcases:

- âœ… Real-time prediction with model confidence
- ðŸ“Š Model explainability using SHAP
- ðŸ“ˆ Visual dashboards and performance insights
- ðŸ› ï¸ Modular code for training, evaluation, and deployment
- âš™ï¸ Fast and high-accuracy (~80%+) models via Optuna tuning

---

ðŸ”— [**Hosted Web App on Streamlit**](https://titanic-survival-prediction-qbqnfwgafy4h6gg8e7diy9.streamlit.app) - **Click to access Web App**

---

## ðŸ“ Project Structure

```
titanic-survival-prediction/
â”‚
â”œâ”€â”€ .streamlit/                   # Ensure consistent and reliable app behavior across environments.
â”‚   â””â”€â”€ config.toml
â”œâ”€â”€ app.py                        # Entry point for Streamlit app
â”œâ”€â”€ requirements.txt              # Project dependencies
â”‚
â”œâ”€â”€ data/                         # Datasets
â”‚   â”œâ”€â”€ train.csv                 # Primary training dataset
â”‚   â””â”€â”€ titanic_sample.csv        # Backup synthetic dataset
â”‚
â”œâ”€â”€ assets/                       # screenshots and graphs
â”‚    â”œâ”€â”€ about.png
â”‚    â”œâ”€â”€ homepage.png
â”‚    â”œâ”€â”€ model_accuracy_context.png
â”‚    â”œâ”€â”€ model_insights.png
â”‚    â”œâ”€â”€ model_perf_comparison.png
â”‚    â”œâ”€â”€ model_test_acruracy.png
â”‚    â”œâ”€â”€ performance_analysis.png
â”‚    â”œâ”€â”€ prediction_result.png
â”‚    â””â”€â”€ prediction.png
â”‚
â”œâ”€â”€ docs/                         # Documentation files
â”‚   â”œâ”€â”€ user_guide.md
â”‚   â”œâ”€â”€ api_docs.md
â”‚   â”œâ”€â”€ model_cards.md
â”‚   â”œâ”€â”€ deployment_guide.md
â”‚   â”œâ”€â”€ model_registry.md
â”‚   â”œâ”€â”€ monitoring_dashboard.md
â”‚   â””â”€â”€ knowledge_base.md
â”‚
â”œâ”€â”€ models/                       # Trained models and metadata
â”‚   â”œâ”€â”€ best_model.pkl
â”‚   â”œâ”€â”€ feature_names.pkl
â”‚   â””â”€â”€ model_metadata.json
â”‚
â”œâ”€â”€ pages/                        # Streamlit multipage setup
â”‚   â”œâ”€â”€ 1_Home.py
â”‚   â”œâ”€â”€ 2_Prediction.py
â”‚   â”œâ”€â”€ 3_Model_Insights.py
â”‚   â””â”€â”€ 4_About.py
â”‚
â”œâ”€â”€ scripts/                      # Training workflows
â”‚   â””â”€â”€ train_high_performance.py
â”‚
â”œâ”€â”€ src/                          # Modular codebase
â”‚   â”œâ”€â”€ data_loader.py
â”‚   â”œâ”€â”€ feature_engineering.py
â”‚   â”œâ”€â”€ data_processor.py
â”‚   â”œâ”€â”€ model_loader.py
â”‚   â”œâ”€â”€ prediction_utils.py
â”‚   â””â”€â”€ visualization_utils.py
â”‚
â””â”€â”€ README.md 
```

## âš™ï¸ `.streamlit/config.toml` â€“ App Configuration

- This directory contains configuration files that define how the Streamlit app behaves across different environments.

The `config.toml` file ensures:

- **Consistent appearance** (theme, layout, sidebar settings)
- **Reliable behavior** across local and cloud deployments
- **Custom branding** (e.g., title, favicon)

###  ðŸ“Œ Tip

Including `.streamlit/config.toml` in your repo guarantees the app will look and behave the same on every machine or platform it's deployed to.


## ðŸ“Š Dataset Sources

- [`train.csv`](https://www.kaggle.com/datasets/yasserh/titanic-dataset) â€“ Kaggle Titanic dataset  
- [`titanic_sample.csv`](https://github.com/beginerSE/titanic_sample/blob/main/titanic_train_mod.csva) â€“ Realistic synthetic fallback dataset  
- [`Public fallback`](https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv) â€“ Auto-download source if local files are missing  

## âœ… Model Training Summary

This section summarizes results from running:

```bash
python scripts/train_high_performance.py
```

### âš™ï¸ Feature Engineering

```
ðŸš€ FIXED High-Performance Training for 80%+ Accuracy
============================================================
âœ… Loaded existing dataset: (891, 12)
ðŸ”§ Applying feature engineering...
Starting enhanced feature engineering...
âœ“ Title extraction completed
âœ“ Family features created
âœ“ Fare features created
âœ“ Age features created
âœ“ Cabin features created
âœ“ Ticket features created
âœ“ Name features created
âœ“ Interaction features created
âœ“ Converting data types for compatibility...
âœ“ Enhanced feature engineering completed! New shape: (891, 62)
âœ… Features created: (891, 62)
ðŸ”§ Selected 12 high-impact features:
['Pclass', 'Sex', 'Age', 'Fare', 'Embarked', 'Title', 'FamilySize', 'IsAlone', 'FarePerPerson', 'CabinLetter', 'HasCabin', 'IsChild']
ðŸ“Š Final training features: 12
ðŸ“Š Feature names: [...]
```

### ðŸ¤– Model Results

| Model                    | Accuracy | CV Mean | CV Std |
|--------------------------|----------|---------|--------|
| RandomForest       | 81.01%   | 0.7471  | Â±0.0296 |
| XGBoost            | 81.56%   | 0.7345  | Â±0.0161 |
| LogisticRegression | **82.12%** | **0.7598**  | Â±0.0194 |

ðŸ† **Best Model**: `LogisticRegression`  
ðŸŽ¯ **Target Achieved**: âœ… 80%+ Accuracy  
ðŸ’¾ **Saved To**: `models/best_model.pkl` + metadata + feature names

## â–¶ï¸ Running the Web App

### 1. Clone the Repository

```bash
git clone https://github.com/ShubhamS168/titanic-survival-prediction
cd titanic-survival-prediction
```

### 2. Create and Activate Virtual Environment

```bash
python -m venv titanic_env
# Windows
titanic_env\Scripts\activate
# Linux/macOS
source titanic_env/bin/activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Launch the App

```bash
streamlit run app.py
```

ðŸ“ Navigate to [http://localhost:8501](http://localhost:8501)

---

### ðŸ“¸ Web App Preview

![Homepage Screenshot](assets/homepage.png)
*Figure 1: Home page*

![Prediction Page](assets/prediction.png)
*Figure 2: Real-time prediction page where users input passenger details*

![Model Insights](assets/model_insights.png)
*Figure 3: Model Insights page*

![Model Insights](assets/about.png)
*Figure 4: Screenshot of the About page*

![Model Insights](assets/prediction_result.png)
*Figure 5: Showing prediction result - page after user prediction*

![Model Insights](assets/model_perf_comparison.png)
*Figure 6: Comparison of multiple model performances*

![Model Insights](assets/model_test_accruracy.png)
*Figure 7: Showing test_accuracy of each model*

![Model Insights](assets/model_accuracy_context.png)
*Figure 8: Visual context around model accuracy*

![Model Insights](assets/performance_analysis.png)
*Figure 9: showing performance analysis expectations table*


---


## ðŸ“Œ Pages & Functionality

| Page                | Description                                                                 |
|---------------------|-----------------------------------------------------------------------------|
| ðŸ  Home             | Dataset summary, model overview, key performance metrics                   |
| ðŸŽ¯ Make Prediction  | User input for passenger details, real-time prediction, confidence gauge    |
| ðŸ“Š Model Insights   | Feature importance, SHAP explanations, model comparison charts              |
| â„¹ï¸ About            | Project overview, training workflow, customization & deployment steps       |

## ðŸ’¡ Customization Guidelines

- ðŸ”„ **Data**: Replace `data/train.csv` with your own dataset  
- ðŸ› ï¸ **Model Tuning**: Adjust `train_high_performance.py` for Optuna ranges  
- ðŸ“ **Feature Engineering**: Edit `src/feature_engineering.py` for new ideas  
- ðŸŽ¨ **UI Styling**: Customize CSS in `app.py`  
- ðŸŒ **Deployment**: Upload to Streamlit Community Cloud, Heroku, or Docker  

## ðŸ“¬ Credits

- **Author**: [**Shubham Sourav**](https://github.com/ShubhamS168) - *Data Science Intern at Celebal Technologies*
- **Dataset**: Kaggle Titanic, GitHub Synthetic  
- **Resources Used**:
  - [Streamlit Docs](https://docs.streamlit.io/)
  - [Machine Learning Mastery â€“ Streamlit Guide](https://machinelearningmastery.com/how-to-quickly-deploy-machine-learning-models-streamlit/)


---

## ðŸ“¬ Contact

For any queries, feedback, or collaboration, feel free to connect:

ðŸ“§ **Email:** [shubhamsourav475@gmail.com](mailto:shubhamsourav475@gmail.com)

---

> ðŸ“ **Note:**  
> This repository is maintained as part of the CSI (Celebal Summer Internship) program and is intended for educational use.


## ðŸ“š Project Goal Reminder

**Deploying Machine Learning Models with Streamlit**

The objective of this project is to **develop a web application using Streamlit** that effectively deploys a trained machine learning model. The application is designed to:

- âœ… Allow users to **input custom data** through an interactive interface  
- ðŸŽ¯ Provide **real-time predictions** based on the trained model  
- ðŸ“Š Help users **understand model outputs** using intuitive visualizations  

This project serves as a practical exercise to make machine learning models more **accessible, interpretable, and user-friendly**, simulating real-world deployment scenarios.


---

## ðŸ“¬ Contact

For any queries, feedback, or collaboration, feel free to connect:

ðŸ“§ **Email:** [shubhamsourav475@gmail.com](mailto:shubhamsourav475@gmail.com)

---

> ðŸ“ **Note:**  
> This repository is maintained as part of the CSI (Celebal Summer Internship) program and is intended for educational use.

## ðŸªª License

Distributed under the MIT License.  
Â© 2025 Shubham Sourav. All rights reserved.