# ğŸš¢ Deploying Machine Learning Models with Streamlit â€“ Titanic Survival Prediction

## ğŸ“˜ Overview

This project demonstrates a **production-ready machine learning deployment pipeline** using **Streamlit** to predict Titanic passenger survival based on engineered features and optimized models. The app enables real-time predictions, model explanations via SHAP, and intuitive dashboards for users.

The solution showcases:

- âœ… Real-time prediction with model confidence
- ğŸ“Š Model explainability using SHAP
- ğŸ“ˆ Visual dashboards and performance insights
- ğŸ› ï¸ Modular code for training, evaluation, and deployment
- âš™ï¸ Fast and high-accuracy (~80%+) models via Optuna tuning

ğŸ”— **Hosted Web App**: *[Add your deployed Streamlit app link here]*

## ğŸ“ Project Structure

```
Assignment/
â””â”€â”€ week 7/
    â”œâ”€â”€ .streamlit/                   # Ensure consistent and reliable app behavior across environments.
    â”‚   â””â”€â”€ config.toml
    â”œâ”€â”€ app.py                        # Entry point for Streamlit app
    â”œâ”€â”€ requirements.txt              # Project dependencies
    â”‚
    â”œâ”€â”€ data/                         # Datasets
    â”‚   â”œâ”€â”€ train.csv                 # Primary training dataset
    â”‚   â””â”€â”€ titanic_sample.csv        # Backup synthetic dataset
    â”‚
    â”œâ”€â”€ docs/                         # Documentation files
    â”‚   â”œâ”€â”€ user_guide.md
    â”‚   â”œâ”€â”€ api_docs.md
    â”‚   â”œâ”€â”€ model_cards.md
    â”‚   â”œâ”€â”€ deployment_guide.md
    â”‚   â”œâ”€â”€ model_registry.md
    â”‚   â”œâ”€â”€ monitoring_dashboard.md
    â”‚   â””â”€â”€ knowledge_base.md
    â”‚
    â”œâ”€â”€ models/                       # Trained models and metadata
    â”‚   â”œâ”€â”€ best_model.pkl
    â”‚   â”œâ”€â”€ feature_names.pkl
    â”‚   â””â”€â”€ model_metadata.json
    â”‚
    â”œâ”€â”€ pages/                        # Streamlit multipage setup
    â”‚   â”œâ”€â”€ 1_Home.py
    â”‚   â”œâ”€â”€ 2_Prediction.py
    â”‚   â”œâ”€â”€ 3_Model_Insights.py
    â”‚   â””â”€â”€ 4_About.py
    â”‚
    â”œâ”€â”€ scripts/                      # Training workflows
    â”‚   â””â”€â”€ train_high_performance.py
    â”‚
    â”œâ”€â”€ src/                          # Modular codebase
    â”‚   â”œâ”€â”€ data_loader.py
    â”‚   â”œâ”€â”€ feature_engineering.py
    â”‚   â”œâ”€â”€ data_processor.py
    â”‚   â”œâ”€â”€ model_loader.py
    â”‚   â”œâ”€â”€ prediction_utils.py
    â”‚   â””â”€â”€ visualization_utils.py
    â”‚
    â””â”€â”€ README.md 
```

## âš™ï¸ `.streamlit/config.toml` â€“ App Configuration

- This directory contains configuration files that define how the Streamlit app behaves across different environments.

The `config.toml` file ensures:

- **Consistent appearance** (theme, layout, sidebar settings)
- **Reliable behavior** across local and cloud deployments
- **Custom branding** (e.g., title, favicon)

###  ğŸ“Œ Tip

Including `.streamlit/config.toml` in your repo guarantees the app will look and behave the same on every machine or platform it's deployed to.


## ğŸ“Š Dataset Sources

- [`train.csv`](https://www.kaggle.com/datasets/yasserh/titanic-dataset) â€“ Kaggle Titanic dataset  
- [`titanic_sample.csv`](https://github.com/beginerSE/titanic_sample/blob/main/titanic_train_mod.csva) â€“ Realistic synthetic fallback dataset  
- [Public fallback](https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv) â€“ Auto-download source if local files are missing  

## âœ… Model Training Summary

This section summarizes results from running:

```bash
python scripts/train_high_performance.py
```

### âš™ï¸ Feature Engineering

```
ğŸš€ FIXED High-Performance Training for 80%+ Accuracy
============================================================
âœ… Loaded existing dataset: (891, 12)
ğŸ”§ Applying feature engineering...
Starting enhanced feature engineering...
âœ“ Title extraction completed
âœ“ Family features created
âœ“ Fare features created
âœ“ Age features created
âœ“ Cabin features created
âœ“ Ticket features created
âœ“ Name features created
âœ“ Interaction features created
âœ“ Converting data types for compatibility...
âœ“ Enhanced feature engineering completed! New shape: (891, 62)
âœ… Features created: (891, 62)
ğŸ”§ Selected 12 high-impact features:
['Pclass', 'Sex', 'Age', 'Fare', 'Embarked', 'Title', 'FamilySize', 'IsAlone', 'FarePerPerson', 'CabinLetter', 'HasCabin', 'IsChild']
ğŸ“Š Final training features: 12
ğŸ“Š Feature names: [...]
```

### ğŸ¤– Model Results

| Model                    | Accuracy | CV Mean | CV Std |
|--------------------------|----------|---------|--------|
| RandomForest       | 81.01%   | 0.7471  | Â±0.0296 |
| XGBoost            | 81.56%   | 0.7345  | Â±0.0161 |
| LogisticRegression | **82.12%** | **0.7598**  | Â±0.0194 |

ğŸ† **Best Model**: `LogisticRegression`  
ğŸ¯ **Target Achieved**: âœ… 80%+ Accuracy  
ğŸ’¾ **Saved To**: `models/best_model.pkl` + metadata + feature names

## â–¶ï¸ Running the Web App

### 1. Clone the Repository

```bash
git clone https://github.com/ShubhamS168/Celebal-CSI-Data-Science/tree/main
cd Assignment/Week 7/
```

### 2. Create and Activate Virtual Environment

```bash
python -m venv titanic_env
# Windows
titanic_env\Scripts\activate
# Linux/macOS
source titanic_env/bin/activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Launch the App

```bash
streamlit run app.py
```

ğŸ“ Navigate to [http://localhost:8501](http://localhost:8501)

## ğŸ“Œ Pages & Functionality

| Page                | Description                                                                 |
|---------------------|-----------------------------------------------------------------------------|
| ğŸ  Home             | Dataset summary, model overview, key performance metrics                   |
| ğŸ¯ Make Prediction  | User input for passenger details, real-time prediction, confidence gauge    |
| ğŸ“Š Model Insights   | Feature importance, SHAP explanations, model comparison charts              |
| â„¹ï¸ About            | Project overview, training workflow, customization & deployment steps       |

## ğŸ’¡ Customization Guidelines

- ğŸ”„ **Data**: Replace `data/train.csv` with your own dataset  
- ğŸ› ï¸ **Model Tuning**: Adjust `train_high_performance.py` for Optuna ranges  
- ğŸ“ **Feature Engineering**: Edit `src/feature_engineering.py` for new ideas  
- ğŸ¨ **UI Styling**: Customize CSS in `app.py`  
- ğŸŒ **Deployment**: Upload to Streamlit Community Cloud, Heroku, or Docker  

## ğŸ“¬ Credits

- **Author**: *Shubham Sourav*  
- **Dataset**: Kaggle Titanic, GitHub Synthetic  
- **Resources Used**:
  - [Streamlit Docs](https://docs.streamlit.io/)
  - [Machine Learning Mastery â€“ Streamlit Guide](https://machinelearningmastery.com/how-to-quickly-deploy-machine-learning-models-streamlit/)

## ğŸªª License

Distributed under the MIT License.  
Â© 2025 Shubham Sourav. All rights reserved.