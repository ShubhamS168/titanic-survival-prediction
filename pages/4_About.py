"""
About page for the Deployment-Focused Titanic Survival Prediction App
"""

import streamlit as st
import pandas as pd
import plotly.express as px

st.title("‚ÑπÔ∏è About This Deployment")
st.markdown("### *Production Machine Learning System*")
st.markdown("---")

# Project overview
st.markdown("## üö¢ Project Overview")

st.markdown("""
This **Titanic Survival Prediction System** demonstrates a complete **production machine learning deployment** 
using Streamlit. Unlike training-focused prototypes, this system showcases real-world ML engineering practices 
with pre-trained models, instant predictions, and comprehensive model monitoring.

### üéØ Deployment Objectives

This production system demonstrates:

- **Model Deployment**: Pre-trained models loaded and cached for instant predictions
- **Production Architecture**: Separation of training (offline) and serving (online) components  
- **User Experience**: Professional interface focused on end-user needs
- **Model Interpretability**: Comprehensive explanations and confidence scoring
- **System Monitoring**: Performance tracking and model insights
- **Error Handling**: Robust error management and graceful degradation
""")

# Technical architecture
st.markdown("---")
st.markdown("## üèóÔ∏è System Architecture")

col1, col2 = st.columns(2)

with col1:
    st.markdown("""
    ### üõ†Ô∏è Technology Stack
    
    **Frontend Layer:**
    - Streamlit: Interactive web interface
    - Plotly: Dynamic visualizations  
    - HTML/CSS: Custom styling
    
    **ML Pipeline:**
    - Scikit-learn: Production ML pipeline
    - XGBoost: Advanced algorithms
    - Joblib: Model serialization
    
    **Data Processing:**
    - Pandas/NumPy: Data manipulation
    - Custom processors: Feature engineering
    """)

with col2:
    st.markdown("""
    ### üîß Production Features
    
    **Performance:**
    - Model caching: Sub-100ms predictions
    - Efficient loading: Models cached in memory
    - Scalable architecture: Ready for load balancing
    
    **Reliability:**
    - Error handling: Graceful failure modes
    - Input validation: Comprehensive checks
    - Monitoring: Performance tracking
    
    **Maintainability:**
    - Modular design: Separated concerns
    - Version control: Model versioning
    - Documentation: Comprehensive guides
    """)

# Deployment vs Training comparison
st.markdown("---")
st.markdown("## üîÑ Deployment vs Training Architecture")

comparison_data = {
    'Aspect': [
        'Primary Focus', 'Model State', 'User Experience', 'Performance', 
        'Architecture', 'Scalability', 'Monitoring', 'Use Case'
    ],
    'Training App': [
        'Model experimentation', 'Training in real-time', 'Data scientist focused', 
        'Slow (training delays)', 'Monolithic', 'Limited', 'Development metrics', 
        'Research & development'
    ],
    'Deployment App': [
        'User predictions', 'Pre-trained models', 'End-user focused',
        'Fast (<100ms)', 'Modular', 'Production ready', 'System monitoring',
        'Production serving'
    ]
}

st.dataframe(
    pd.DataFrame(comparison_data), 
    use_container_width=True, 
    hide_index=True
)

# Model information
st.markdown("---")
st.markdown("## ü§ñ Model Specifications")

try:
    import sys
    sys.path.append('src')
    from model_loader import get_model_info
    
    metadata = get_model_info()
    
    if metadata:
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown(f"""
            ### üìä Current Model
            
            **Algorithm:** {metadata['model_name']}  
            **Version:** 1.0  
            **Training Date:** {metadata['training_date'][:10]}  
            **Test Accuracy:** {metadata['test_accuracy']:.1%}  
            **Features:** {metadata['feature_count']} engineered features  
            **Training Data:** {metadata['training_samples']} samples  
            """)
        
        with col2:
            if 'all_results' in metadata:
                results_df = pd.DataFrame(metadata['all_results'])
                
                fig = px.bar(
                    results_df,
                    x='model_name',
                    y='test_accuracy', 
                    title="Model Selection Process",
                    color='test_accuracy',
                    color_continuous_scale='viridis'
                )
                fig.update_layout(height=300)
                st.plotly_chart(fig, use_container_width=True)

except Exception:
    st.info("Model information will be displayed when the system is fully initialized.")

# Dataset information
st.markdown("---")
st.markdown("## üìã Dataset Information")

st.markdown("""
The **RMS Titanic** dataset contains passenger information from the famous 1912 maritime disaster. 
This dataset has become a standard benchmark in machine learning education due to its ideal characteristics 
for binary classification problems.

### üìä Dataset Characteristics

- **Total Records:** 891 passenger records
- **Features:** 12 original + 60 engineered features  
- **Target:** Binary survival outcome (0=died, 1=survived)
- **Missing Data:** Realistic patterns (~20% age, ~77% cabin)
- **Class Balance:** 38% survived, 62% did not survive
""")

# Feature breakdown
feature_stats = {
    'Feature Category': ['Demographics', 'Economic', 'Family', 'Location', 'Engineered'],
    'Count': [4, 3, 2, 3, 48],
    'Examples': [
        'Age, Sex, Title',
        'Fare, Class, Ticket',
        'Siblings, Parents/Children', 
        'Cabin, Embarked Port',
        'Family size, Fare per person, Age groups'
    ],
    'Importance': ['High', 'High', 'Medium', 'Medium', 'Variable']
}

st.dataframe(pd.DataFrame(feature_stats), use_container_width=True, hide_index=True)

# Performance expectations
st.markdown("---")
st.markdown("## üìà Performance Analysis")

st.markdown("""
### üéØ Accuracy Expectations

Understanding realistic performance expectations is crucial for production ML systems:
""")

performance_ranges = {
    'Performance Tier': ['Excellent (Deployed)', 'Very Good', 'Good', 'Basic', 'Suspicious'],
    'Accuracy Range': ['80-85%', '75-80%', '70-75%', '60-70%', '>90%'],
    'Characteristics': [
        'Production ready, no overfitting',
        'Solid methodology, good features',
        'Baseline with proper validation', 
        'Simple models, basic features',
        'Likely data leakage or overfitting'
    ],
    'Deployment Suitability': ['‚úÖ Ready', '‚úÖ Good', '‚ö†Ô∏è Acceptable', '‚ùå Poor', '‚ùå Unreliable']
}

st.dataframe(pd.DataFrame(performance_ranges), use_container_width=True, hide_index=True)

# Why >90% accuracy is unrealistic
st.markdown("### ‚ö†Ô∏è The 90% Accuracy Myth")

st.error("""
**Why >90% accuracy is unrealistic for Titanic data:**

üö® **Dataset Limitations**: Only 891 samples with significant missing data  
üö® **Historical Chaos**: Disaster involved unpredictable human behavior  
üö® **Feature Constraints**: Limited to passenger manifest information  
üö® **Overfitting Risk**: Complex models memorize rather than learn  
üö® **Data Leakage**: High scores often use information not available at prediction time  
""")

col1, col2 = st.columns(2)

with col1:
    st.markdown("""
    #### üîç Red Flags for Suspicious Accuracy
    
    - Using passenger names or IDs as features
    - Perfect or near-perfect scores (>95%)
    - Lack of proper cross-validation
    - No mention of overfitting prevention
    - Claims without methodology details
    """)

with col2:
    st.markdown("""
    #### ‚úÖ Signs of Legitimate Performance
    
    - Comprehensive cross-validation
    - Realistic feature engineering
    - Proper train/validation/test splits
    - Discussion of limitations
    - Reproducible methodology
    """)

# Historical context
st.markdown("---")
st.markdown("## üìö Historical Context")

st.markdown("""
### üö¢ RMS Titanic Disaster - April 15, 1912

Understanding the historical context helps interpret model predictions and limitations:

#### Key Historical Facts:
- **Route**: Southampton ‚Üí New York City (maiden voyage)
- **Passengers**: ~2,224 people aboard (passengers + crew)
- **Lifeboats**: Only enough for ~1/3 of people aboard  
- **Sinking Time**: ~2 hours 40 minutes from impact to sinking
- **Water Temperature**: Near freezing (28¬∞F / -2¬∞C)
- **Rescue**: RMS Carpathia arrived ~4 hours after sinking

#### Survival Factors Not in Data:
- **Location during impact**: Proximity to lifeboats
- **Individual decisions**: Personal choices during evacuation  
- **Physical condition**: Health, strength, swimming ability
- **Social connections**: Help from crew or other passengers
- **Random chance**: Timing, luck, circumstances
""")

# Survival statistics
survival_stats = {
    'Category': ['Overall', 'Women', 'Men', 'Children (under 16)', '1st Class', '2nd Class', '3rd Class'],
    'Survival Rate': ['38%', '74%', '19%', '52%', '63%', '47%', '24%'],
    'Context': [
        'All passengers combined',
        '"Women and children first" policy',
        'Lower priority in evacuation',
        'Priority in lifeboats',
        'Better cabin locations, early access',
        'Moderate access to lifeboats', 
        'Below deck, limited access'
    ]
}

st.dataframe(pd.DataFrame(survival_stats), use_container_width=True, hide_index=True)

# Production deployment
st.markdown("---")
st.markdown("## üöÄ Production Deployment Guide")

st.markdown("""
### üîß System Requirements

**Minimum Requirements:**
- Python 3.8+
- 4GB RAM
- 1GB disk space
- Internet connection (for Streamlit)

**Recommended for Production:**
- Python 3.10+
- 8GB RAM  
- 5GB disk space
- Load balancer (for high traffic)
""")

# Deployment options
deployment_options = {
    'Platform': ['Streamlit Cloud', 'Heroku', 'AWS EC2', 'Docker', 'Local'],
    'Difficulty': ['Easy', 'Medium', 'Hard', 'Medium', 'Easy'],
    'Cost': ['Free', 'Free tier', 'Pay per use', 'Infrastructure', 'None'],
    'Scalability': ['Medium', 'Medium', 'High', 'High', 'Low'],
    'Best For': ['Demos', 'Small apps', 'Enterprise', 'Any platform', 'Development']
}

st.dataframe(pd.DataFrame(deployment_options), use_container_width=True, hide_index=True)



# Future enhancements
st.markdown("---")
st.markdown("## üîÆ Future Enhancements")

col1, col2 = st.columns(2)

with col1:
    st.markdown("""
    ### üéØ Short Term (Next Release)
    
    - **A/B Testing**: Multiple model comparison
    - **Batch Predictions**: CSV file upload
    - **Model Explanation**: SHAP value integration
    - **Performance Monitoring**: Real-time metrics
    - **API Endpoints**: REST API for integration
    """)

with col2:
    st.markdown("""
    ### üöÄ Long Term (Future Versions)
    
    - **Auto-retraining**: Periodic model updates
    - **Ensemble Models**: Multiple algorithm combination
    - **Feature Store**: Centralized feature management
    - **MLOps Pipeline**: Full CI/CD integration
    - **Multi-tenant**: Support for multiple datasets
    """)

# Contact and support
st.markdown("---")
st.markdown("## üìû Support & Documentation")

col1, col2 = st.columns(2)



with col1:
    st.markdown("""
    ### üìö Documentation

    - [**User Guide**](docs/user_guide.md) ‚Äì Complete usage instructions
    - [**API Docs**](docs/api_docs.md) ‚Äì REST API interface
    - [**Model Cards**](docs/model_cards.md) ‚Äì Details of trained models
    - [**Deployment Guide**](docs/deployment_guide.md) ‚Äì Setup guide
    """)

with col2:
    st.markdown("""
    ### üîó Resources

    - [**GitHub Repository**](https://github.com/ShubhamS168/Celebal-CSI-Data-Science/tree/main) ‚Äì Source & issues
    - [**Model Registry**](docs/model_registry.md) ‚Äì Tracked model files
    - [**Monitoring Dashboard**](docs/monitoring_dashboard.md) ‚Äì Performance metrics
    - [**Knowledge Base**](docs/knowledge_base.md) ‚Äì FAQs & solutions
    """)




st.success("""
### ‚úÖ Production Ready

This Titanic Survival Prediction System demonstrates **production-grade machine learning deployment** 
with proper model management, user experience design, and system monitoring. 

**Key Achievement**: Successfully transitioned from a training-focused prototype to a 
deployment-ready system suitable for real-world use cases.
""")

st.markdown("---")
st.markdown("*Thank you for exploring this production machine learning deployment!*")
